{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14774,"databundleVersionId":875431,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import cohen_kappa_score\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport cv2\nfrom PIL import Image\nimport timm\nfrom multiprocessing import Pool\nfrom tqdm import tqdm\nfrom torchvision import transforms\nfrom torch.optim.lr_scheduler import LambdaLR","metadata":{"execution":{"iopub.status.busy":"2024-06-23T22:36:15.463480Z","iopub.execute_input":"2024-06-23T22:36:15.463829Z","iopub.status.idle":"2024-06-23T22:36:22.412291Z","shell.execute_reply.started":"2024-06-23T22:36:15.463802Z","shell.execute_reply":"2024-06-23T22:36:22.411482Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"## for removing file if required\nimport shutil\n\ntry:\n    shutil.rmtree(\"/kaggle/working/train\")\n    \n    model_file_to_delete =\"/kaggle/working/models\"\n\n    if os.path.isfile(model_file_to_delete):\n        os.remove(model_file_to_delete)\n    \nexcept:\n    print(\"No such directories\")","metadata":{"execution":{"iopub.status.busy":"2024-06-23T22:36:22.414202Z","iopub.execute_input":"2024-06-23T22:36:22.414652Z","iopub.status.idle":"2024-06-23T22:36:22.420691Z","shell.execute_reply.started":"2024-06-23T22:36:22.414619Z","shell.execute_reply":"2024-06-23T22:36:22.419864Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"No such directories\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Loading Data","metadata":{}},{"cell_type":"code","source":"def load_data(data_dir):\n    train_csv = os.path.join(data_dir, 'train.csv')\n    test_csv = os.path.join(data_dir, 'test.csv')\n    \n    train = pd.read_csv(train_csv)\n    test = pd.read_csv(test_csv)\n    \n    train_dir = os.path.join(data_dir, 'train_images/')\n    test_dir = os.path.join(data_dir, 'test_images/')\n    \n    train['file_path'] = train['id_code'].map(lambda x: os.path.join(train_dir, '{}.png'.format(x)))\n    test['file_path'] = test['id_code'].map(lambda x: os.path.join(test_dir, '{}.png'.format(x)))\n    \n    train['file_name'] = train[\"id_code\"] + \".png\"\n    test['file_name'] = test[\"id_code\"] + \".png\"\n    \n    train['diagnosis'] = train['diagnosis'].astype(str)\n    \n    return train, test","metadata":{"execution":{"iopub.status.busy":"2024-06-23T22:36:22.421742Z","iopub.execute_input":"2024-06-23T22:36:22.422004Z","iopub.status.idle":"2024-06-23T22:36:22.432666Z","shell.execute_reply.started":"2024-06-23T22:36:22.421982Z","shell.execute_reply":"2024-06-23T22:36:22.431918Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/aptos2019-blindness-detection/'\ntrain_df, test_df = load_data(data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T22:36:22.433606Z","iopub.execute_input":"2024-06-23T22:36:22.433866Z","iopub.status.idle":"2024-06-23T22:36:22.484444Z","shell.execute_reply.started":"2024-06-23T22:36:22.433845Z","shell.execute_reply":"2024-06-23T22:36:22.483621Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(train_df.shape)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-23T22:36:22.486773Z","iopub.execute_input":"2024-06-23T22:36:22.487034Z","iopub.status.idle":"2024-06-23T22:36:22.501183Z","shell.execute_reply.started":"2024-06-23T22:36:22.487012Z","shell.execute_reply":"2024-06-23T22:36:22.500331Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"(3662, 4)\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"        id_code diagnosis                                          file_path  \\\n0  000c1434d8d7         2  /kaggle/input/aptos2019-blindness-detection/tr...   \n1  001639a390f0         4  /kaggle/input/aptos2019-blindness-detection/tr...   \n2  0024cdab0c1e         1  /kaggle/input/aptos2019-blindness-detection/tr...   \n3  002c21358ce6         0  /kaggle/input/aptos2019-blindness-detection/tr...   \n4  005b95c28852         0  /kaggle/input/aptos2019-blindness-detection/tr...   \n\n          file_name  \n0  000c1434d8d7.png  \n1  001639a390f0.png  \n2  0024cdab0c1e.png  \n3  002c21358ce6.png  \n4  005b95c28852.png  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_code</th>\n      <th>diagnosis</th>\n      <th>file_path</th>\n      <th>file_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000c1434d8d7</td>\n      <td>2</td>\n      <td>/kaggle/input/aptos2019-blindness-detection/tr...</td>\n      <td>000c1434d8d7.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>001639a390f0</td>\n      <td>4</td>\n      <td>/kaggle/input/aptos2019-blindness-detection/tr...</td>\n      <td>001639a390f0.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0024cdab0c1e</td>\n      <td>1</td>\n      <td>/kaggle/input/aptos2019-blindness-detection/tr...</td>\n      <td>0024cdab0c1e.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>002c21358ce6</td>\n      <td>0</td>\n      <td>/kaggle/input/aptos2019-blindness-detection/tr...</td>\n      <td>002c21358ce6.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>005b95c28852</td>\n      <td>0</td>\n      <td>/kaggle/input/aptos2019-blindness-detection/tr...</td>\n      <td>005b95c28852.png</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(test_df.shape)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-23T22:36:22.502209Z","iopub.execute_input":"2024-06-23T22:36:22.502553Z","iopub.status.idle":"2024-06-23T22:36:22.512094Z","shell.execute_reply.started":"2024-06-23T22:36:22.502527Z","shell.execute_reply":"2024-06-23T22:36:22.511100Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"(1928, 3)\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"        id_code                                          file_path  \\\n0  0005cfc8afb6  /kaggle/input/aptos2019-blindness-detection/te...   \n1  003f0afdcd15  /kaggle/input/aptos2019-blindness-detection/te...   \n2  006efc72b638  /kaggle/input/aptos2019-blindness-detection/te...   \n3  00836aaacf06  /kaggle/input/aptos2019-blindness-detection/te...   \n4  009245722fa4  /kaggle/input/aptos2019-blindness-detection/te...   \n\n          file_name  \n0  0005cfc8afb6.png  \n1  003f0afdcd15.png  \n2  006efc72b638.png  \n3  00836aaacf06.png  \n4  009245722fa4.png  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_code</th>\n      <th>file_path</th>\n      <th>file_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0005cfc8afb6</td>\n      <td>/kaggle/input/aptos2019-blindness-detection/te...</td>\n      <td>0005cfc8afb6.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>003f0afdcd15</td>\n      <td>/kaggle/input/aptos2019-blindness-detection/te...</td>\n      <td>003f0afdcd15.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>006efc72b638</td>\n      <td>/kaggle/input/aptos2019-blindness-detection/te...</td>\n      <td>006efc72b638.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00836aaacf06</td>\n      <td>/kaggle/input/aptos2019-blindness-detection/te...</td>\n      <td>00836aaacf06.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>009245722fa4</td>\n      <td>/kaggle/input/aptos2019-blindness-detection/te...</td>\n      <td>009245722fa4.png</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Pre-Processing","metadata":{}},{"cell_type":"code","source":"def crop_img(img, percentage):\n    \n    img_arr = np.array(img)\n    img_gray = cv2.cvtColor(img_arr, cv2.COLOR_BGR2GRAY)\n    \n    threshold = img_gray > 0.1 * np.mean(img_gray[img_gray != 0])\n    row_sums = np.sum(threshold, axis=1)\n    col_sums = np.sum(threshold, axis=0)\n    \n    rows = np.where(row_sums > img_arr.shape[1] * percentage)[0]\n    cols = np.where(col_sums > img_arr.shape[0] * percentage)[0]\n    \n    min_row, min_col = np.min(rows), np.min(cols)\n    max_row, max_col = np.max(rows), np.max(cols)\n    \n    crop_img = img_arr[min_row : max_row + 1, min_col : max_col + 1]\n    \n    return Image.fromarray(crop_img)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T22:36:22.513454Z","iopub.execute_input":"2024-06-23T22:36:22.513710Z","iopub.status.idle":"2024-06-23T22:36:22.521362Z","shell.execute_reply.started":"2024-06-23T22:36:22.513689Z","shell.execute_reply":"2024-06-23T22:36:22.520483Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def resize_maintain_aspect(img, desired_size):\n    old_width, old_height = img.size\n    aspect_ratio = old_width / old_height\n\n    if aspect_ratio > 1:\n        new_width = desired_size\n        new_height = int(desired_size / aspect_ratio)\n    else:\n        new_height = desired_size\n        new_width = int(desired_size * aspect_ratio)\n\n    resized_img = img.resize((new_width, new_height), Image.ANTIALIAS)\n    \n    padded_image = Image.new(\"RGB\", (desired_size, desired_size))\n    x_offset = (desired_size - new_width) // 2\n    y_offset = (desired_size - new_height) // 2\n    padded_image.paste(resized_img, (x_offset, y_offset))\n    \n    return padded_image","metadata":{"execution":{"iopub.status.busy":"2024-06-23T22:36:22.522333Z","iopub.execute_input":"2024-06-23T22:36:22.522626Z","iopub.status.idle":"2024-06-23T22:36:22.533912Z","shell.execute_reply.started":"2024-06-23T22:36:22.522604Z","shell.execute_reply":"2024-06-23T22:36:22.533103Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def save_single(args):\n    image_path, output_path_folder, percentage, output_size = args\n    image = Image.open(image_path)\n    \n    # Display the image\n    #plt.imshow(image)\n    #plt.title('Original Image')\n    #plt.show()\n    \n    croped_img = crop_img(image,percentage)\n    image_resized = resize_maintain_aspect(croped_img, desired_size=output_size[0])\n    \n    #print(output_path_folder)\n    #print(image_path)\n    output_image_path = os.path.basename(image_path)\n    # Save the resized image\n    output_file_path = os.path.join(output_path_folder, output_image_path)\n    #print(output_file_path)\n    image_resized.save(output_file_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T22:36:22.534813Z","iopub.execute_input":"2024-06-23T22:36:22.535039Z","iopub.status.idle":"2024-06-23T22:36:22.544583Z","shell.execute_reply.started":"2024-06-23T22:36:22.535019Z","shell.execute_reply":"2024-06-23T22:36:22.543751Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def fast_image_resize(df, output_path_folder, percentage, output_size=None):\n    \"\"\"Uses multiprocessing to make it fast\"\"\"\n    if not output_size:\n        warnings.warn(\"Need to specify output_size! For example: output_size=100\")\n        return\n\n    if not os.path.exists(output_path_folder):\n        os.makedirs(output_path_folder)\n        \n    jobs = []\n    for df_item in range(len(df)):\n        image_path = df.file_path.iloc[df_item]\n        #print(image_path)\n        job = (image_path, output_path_folder, percentage, output_size)\n        jobs.append(job)\n    \n    \"\"\"\n    results = []\n    for job in tqdm(jobs, total=len(jobs)):\n        result = save_single(job)\n        results.append(result)\n    \"\"\"\n    with Pool() as p:\n        list(tqdm(p.imap_unordered(save_single, jobs), total=len(jobs)))","metadata":{"execution":{"iopub.status.busy":"2024-06-23T22:36:22.545836Z","iopub.execute_input":"2024-06-23T22:36:22.546568Z","iopub.status.idle":"2024-06-23T22:36:22.555042Z","shell.execute_reply.started":"2024-06-23T22:36:22.546539Z","shell.execute_reply":"2024-06-23T22:36:22.554291Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"percentage = 0.01\nfast_image_resize(train_df, \"/kaggle/working/train/images_resized_150/\",percentage, output_size=(100, 100))","metadata":{"execution":{"iopub.status.busy":"2024-06-23T22:36:22.556948Z","iopub.execute_input":"2024-06-23T22:36:22.557561Z","iopub.status.idle":"2024-06-23T22:41:49.650082Z","shell.execute_reply.started":"2024-06-23T22:36:22.557524Z","shell.execute_reply":"2024-06-23T22:41:49.649017Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"  0%|          | 0/3662 [00:00<?, ?it/s]/tmp/ipykernel_34/3153832717.py:12: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n  resized_img = img.resize((new_width, new_height), Image.ANTIALIAS)\n  0%|          | 1/3662 [00:00<11:15,  5.42it/s]/tmp/ipykernel_34/3153832717.py:12: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n  resized_img = img.resize((new_width, new_height), Image.ANTIALIAS)\n  0%|          | 2/3662 [00:00<16:06,  3.79it/s]/tmp/ipykernel_34/3153832717.py:12: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n  resized_img = img.resize((new_width, new_height), Image.ANTIALIAS)\n/tmp/ipykernel_34/3153832717.py:12: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n  resized_img = img.resize((new_width, new_height), Image.ANTIALIAS)\n100%|██████████| 3662/3662 [05:26<00:00, 11.20it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Model Implementation - Ensambling \n#### EfficientNet_b5 + ResNet18","metadata":{}},{"cell_type":"code","source":"class BlindnessDataset(Dataset):\n    def __init__(self, csv_file, root_dir, transform=None, augmentations=None, max_count=None, test=False):\n        self.annotations = pd.read_csv(csv_file)\n        self.root_dir = root_dir\n        self.transform = transform\n        #self.augmentations = augmentations\n        self.max_count = max_count\n        self.test = test\n        \n        if not test:\n            self.class_counts = self.annotations['diagnosis'].value_counts().sort_index()\n        else:\n            self.class_counts = None\n        \n        if max_count:\n            self.oversample(max_count)\n    \n    def oversample(self, max_count): ## Over sampling classes to balance\n        samples = []\n        for diagnosis in self.class_counts.index:\n            class_samples = self.annotations[self.annotations['diagnosis'] == diagnosis]\n            oversampled_class = class_samples.sample(max_count, replace=True)\n            samples.append(oversampled_class)\n        self.annotations = pd.concat(samples).reset_index(drop=True)\n    \n    def __len__(self):\n        return len(self.annotations)\n    \n    def __getitem__(self, idx):\n        img_name = os.path.join(self.root_dir, self.annotations.iloc[idx, 0] + '.png')\n        image = Image.open(img_name).convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        if self.test:\n            return image\n                \n        label = int(self.annotations.iloc[idx, 1])\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-06-23T22:41:49.651897Z","iopub.execute_input":"2024-06-23T22:41:49.652623Z","iopub.status.idle":"2024-06-23T22:41:49.663467Z","shell.execute_reply.started":"2024-06-23T22:41:49.652582Z","shell.execute_reply":"2024-06-23T22:41:49.662604Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def select_model(model_name):\n    if model_name == 'efficientnet_b0':\n        return timm.create_model('efficientnet_b0', pretrained=True, num_classes=5)\n    elif model_name == 'efficientnet_b1':\n        return timm.create_model('efficientnet_b1', pretrained=True, num_classes=5)\n    elif model_name == 'efficientnet_b2':\n        return timm.create_model('efficientnet_b2', pretrained=True, num_classes=5)\n    elif model_name == 'efficientnet_b3':\n        return timm.create_model('efficientnet_b3', pretrained=True, num_classes=5)\n    elif model_name == 'efficientnet_b4':\n        return timm.create_model('efficientnet_b4', pretrained=True, num_classes=5)\n    elif model_name == 'efficientnet_b5':\n        return timm.create_model('efficientnet_b5', pretrained=True, num_classes=5)\n    elif model_name == 'efficientnet_b6':\n        return timm.create_model('efficientnet_b6', pretrained=False, num_classes=5)\n    elif model_name == 'efficientnet_b7':\n        return timm.create_model('efficientnet_b7', pretrained=True, num_classes=5)\n    elif model_name == 'resnet18':\n        model = timm.create_model('resnet18', pretrained=True, num_classes=5)\n        return model","metadata":{"execution":{"iopub.status.busy":"2024-06-23T22:41:49.664573Z","iopub.execute_input":"2024-06-23T22:41:49.664872Z","iopub.status.idle":"2024-06-23T22:41:49.678212Z","shell.execute_reply.started":"2024-06-23T22:41:49.664840Z","shell.execute_reply":"2024-06-23T22:41:49.677418Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def lr_schedule(epoch):\n    if epoch < 10:\n        return 5e-4\n    elif epoch < 16:\n        return 1e-4\n    elif epoch < 22:\n        return 1e-5\n    else:\n        return 1e-3\n        ","metadata":{"execution":{"iopub.status.busy":"2024-06-23T22:41:49.682847Z","iopub.execute_input":"2024-06-23T22:41:49.683103Z","iopub.status.idle":"2024-06-23T22:41:49.691989Z","shell.execute_reply.started":"2024-06-23T22:41:49.683080Z","shell.execute_reply":"2024-06-23T22:41:49.691184Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def train_model(model_name,train_loader,valid_loader):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = select_model(model_name).to(device)\n    criterion = nn.CrossEntropyLoss()\n    \n    if 'resnet' in model_name:\n        optimizer = optim.Adam(model.parameters(), weight_decay=1e-3)\n    else:\n        optimizer = optim.Adam(model.parameters())\n    \n    def lambda_epoch(epoch):\n        return lr_schedule(epoch)\n    \n    def quadratic_weighted_kappa(y_true, y_pred):\n        return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n    \n    scheduler = LambdaLR(optimizer,lr_lambda = lambda_epoch)\n    best_kappa = 0.0\n    \n    print(\"Model: \", model_name)\n    \n    for epoch in range(25):\n        model.train()\n        for images, labels in train_loader:\n            if isinstance(images, Image.Image):  # Check if the image is a PIL image\n                transform = transforms.ToTensor()\n                images = transform(images)\n            else:\n                images = images\n                \n            images, labels = images.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        scheduler.step()\n        \n        model.eval()\n        val_loss = 0\n        val_preds = []\n        val_labels_epoch = []\n        with torch.no_grad():\n            for images, labels in valid_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs,labels)\n                val_loss += loss.item()\n                preds = torch.argmax(outputs, dim=1)\n                val_labels_epoch.extend(labels.cpu().numpy())\n                val_preds.extend(preds.cpu().numpy())\n        \n        #val_predictions.append(val_preds)\n        #val_labels.append(val_labels_epoch)\n        \n        kappa = quadratic_weighted_kappa(val_labels_epoch, val_preds)\n        print(f\"Epoch {epoch+1}/{25}, Validation Loss: {val_loss / len(valid_loader)}\")\n        print(f\"Validation QWK: {kappa}\")\n        \n        if kappa > best_kappa:\n            best_kappa = kappa\n            best_model = model.state_dict()\n    \n            \n    model.load_state_dict(best_model)\n    \n    return model\n\n    ","metadata":{"execution":{"iopub.status.busy":"2024-06-23T22:41:49.693157Z","iopub.execute_input":"2024-06-23T22:41:49.693555Z","iopub.status.idle":"2024-06-23T22:41:49.707952Z","shell.execute_reply.started":"2024-06-23T22:41:49.693525Z","shell.execute_reply":"2024-06-23T22:41:49.707097Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"csv_file = '/kaggle/input/aptos2019-blindness-detection/train.csv'\npros_img_dir = '/kaggle/working/train/images_resized_150'\ntest_csv_file = '/kaggle/input/aptos2019-blindness-detection/test.csv'\ntest_root_dir = '/kaggle/input/aptos2019-blindness-detection/test_images'\nval_csv_file = '/kaggle/working/val.csv'\nval_root_dir = '/kaggle/working/val_images/'\n\nos.makedirs(val_root_dir, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T22:41:49.708969Z","iopub.execute_input":"2024-06-23T22:41:49.709241Z","iopub.status.idle":"2024-06-23T22:41:49.722445Z","shell.execute_reply.started":"2024-06-23T22:41:49.709218Z","shell.execute_reply":"2024-06-23T22:41:49.721678Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([ \n        transforms.Resize((224, 224)), transforms.ToTensor() \n    ])","metadata":{"execution":{"iopub.status.busy":"2024-06-23T22:41:49.723392Z","iopub.execute_input":"2024-06-23T22:41:49.723685Z","iopub.status.idle":"2024-06-23T22:41:49.736259Z","shell.execute_reply.started":"2024-06-23T22:41:49.723662Z","shell.execute_reply":"2024-06-23T22:41:49.735423Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"## Loading the dataset for determination of the class counts\ntemp_dataset = BlindnessDataset(csv_file, pros_img_dir, transform=transform)\nclass_counts = temp_dataset.class_counts\nmax_count = class_counts.max()","metadata":{"execution":{"iopub.status.busy":"2024-06-23T22:41:49.737423Z","iopub.execute_input":"2024-06-23T22:41:49.737999Z","iopub.status.idle":"2024-06-23T22:41:49.764827Z","shell.execute_reply.started":"2024-06-23T22:41:49.737969Z","shell.execute_reply":"2024-06-23T22:41:49.764020Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"dataset = BlindnessDataset(csv_file, pros_img_dir, transform=transform, max_count=max_count)\ntrain_indices, val_indices = train_test_split(list(range(len(dataset))), test_size=0.2, stratify=dataset.annotations.iloc[:, 1])\ntrain_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\nval_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\ntrain_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler)\nval_loader = DataLoader(dataset, batch_size=32, sampler=val_sampler)\n        ","metadata":{"execution":{"iopub.status.busy":"2024-06-23T22:41:49.765970Z","iopub.execute_input":"2024-06-23T22:41:49.766262Z","iopub.status.idle":"2024-06-23T22:41:49.791471Z","shell.execute_reply.started":"2024-06-23T22:41:49.766237Z","shell.execute_reply":"2024-06-23T22:41:49.790806Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"val_annotations = dataset.annotations.iloc[val_indices]\nval_annotations.to_csv(val_csv_file, index=False)\n\nfor idx in val_indices:\n    img_name = dataset.annotations.iloc[idx, 0] + '.png'\n    src_path = os.path.join(pros_img_dir, img_name)\n    dst_path = os.path.join(val_root_dir, img_name)\n    shutil.copy2(src_path, dst_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T22:41:49.792278Z","iopub.execute_input":"2024-06-23T22:41:49.792514Z","iopub.status.idle":"2024-06-23T22:41:50.129445Z","shell.execute_reply.started":"2024-06-23T22:41:49.792494Z","shell.execute_reply":"2024-06-23T22:41:50.128674Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def cross_validate_and_ensemble(train_loader, val_loader):\n    models = {\n        'efficientnet_b5': [],\n        'resnet18': []\n    }\n    \n    for model_type in models.keys():\n        model = train_model(model_type, train_loader, val_loader)\n        models[model_type].append(model)\n    \n    return models\n","metadata":{"execution":{"iopub.status.busy":"2024-06-23T22:41:50.130525Z","iopub.execute_input":"2024-06-23T22:41:50.130798Z","iopub.status.idle":"2024-06-23T22:41:50.137122Z","shell.execute_reply.started":"2024-06-23T22:41:50.130773Z","shell.execute_reply":"2024-06-23T22:41:50.136270Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def get_predicted_labels(predictions):\n    predicted_labels = np.argmax(predictions, axis=1)\n    return predicted_labels","metadata":{"execution":{"iopub.status.busy":"2024-06-23T22:41:50.138121Z","iopub.execute_input":"2024-06-23T22:41:50.138408Z","iopub.status.idle":"2024-06-23T22:41:50.145768Z","shell.execute_reply.started":"2024-06-23T22:41:50.138384Z","shell.execute_reply":"2024-06-23T22:41:50.144945Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def load_ground_truth_labels(test_csv_file):\n    test_df = pd.read_csv(test_csv_file)\n    if test_df.shape[1] > 1:\n        ground_truth_labels = test_df.iloc[:, 1].values\n    else:\n        ground_truth_labels = None\n    return ground_truth_labels","metadata":{"execution":{"iopub.status.busy":"2024-06-23T22:41:50.146889Z","iopub.execute_input":"2024-06-23T22:41:50.147190Z","iopub.status.idle":"2024-06-23T22:41:50.156473Z","shell.execute_reply.started":"2024-06-23T22:41:50.147166Z","shell.execute_reply":"2024-06-23T22:41:50.155519Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def quadratic_weighted_kappa(y_true, y_pred):\n    return cohen_kappa_score(y_true, y_pred, weights='quadratic')","metadata":{"execution":{"iopub.status.busy":"2024-06-23T22:41:50.157515Z","iopub.execute_input":"2024-06-23T22:41:50.157837Z","iopub.status.idle":"2024-06-23T22:41:50.169808Z","shell.execute_reply.started":"2024-06-23T22:41:50.157807Z","shell.execute_reply":"2024-06-23T22:41:50.169033Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def predict_ensemble(models, test_csv_file,test_root_dir): \n    transform = transforms.Compose([ transforms.Resize((224, 224)), transforms.ToTensor() ]) \n    test_dataset = BlindnessDataset(test_csv_file, test_root_dir, transform=transform, test=True)\n    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n    predictions = []\n    \n    for model_type, model_list in models.items():\n        for model in model_list:\n            model.eval() \n            model = model.to(device) \n            model_preds = [] \n            with torch.no_grad(): \n                for images in test_loader: \n                    images = images.to(device) \n                    outputs = model(images) \n                    preds = torch.softmax(outputs, dim=1) \n                    model_preds.append(preds.cpu().numpy()) \n            model_preds = np.concatenate(model_preds, axis=0)\n            #print(f\"{model_type} model predictions shape: {model_preds.shape}\")\n            predictions.append(model_preds)\n    \n    #print(f\"Number of model predictions: {len(predictions)}\")\n    #for i, pred in enumerate(predictions):\n        #print(f\"Shape of predictions from model {i+1}: {pred.shape}\")\n    \n    final_predictions = np.mean(predictions, axis=0)\n    print(f\"Final averaged predictions shape: {final_predictions.shape}\")\n    \n    predicted_labels = get_predicted_labels(final_predictions)\n    \n    ground_truth_labels = load_ground_truth_labels(test_csv_file)\n    \n    if ground_truth_labels is not None:\n        final_kappa = quadratic_weighted_kappa(ground_truth_labels, predicted_labels)\n        print(\"Final Kappa:\", final_kappa)\n    else:\n        final_kappa = None\n        print(\"Ground truth labels are not available in the test CSV file.\")\n    \n    return final_predictions, final_kappa","metadata":{"execution":{"iopub.status.busy":"2024-06-23T22:41:50.170938Z","iopub.execute_input":"2024-06-23T22:41:50.171192Z","iopub.status.idle":"2024-06-23T22:41:50.181810Z","shell.execute_reply.started":"2024-06-23T22:41:50.171171Z","shell.execute_reply":"2024-06-23T22:41:50.181041Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"models = cross_validate_and_ensemble(train_loader, val_loader)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T22:41:50.182740Z","iopub.execute_input":"2024-06-23T22:41:50.182994Z","iopub.status.idle":"2024-06-23T23:33:00.025103Z","shell.execute_reply.started":"2024-06-23T22:41:50.182973Z","shell.execute_reply":"2024-06-23T23:33:00.024137Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/122M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18e04ea096884236a45808a49ba1e5ef"}},"metadata":{}},{"name":"stdout","text":"Model:  efficientnet_b5\nEpoch 1/25, Validation Loss: 3.590219263444867\nValidation QWK: 0.36614959299646754\nEpoch 2/25, Validation Loss: 2.383771632847033\nValidation QWK: 0.5243362831858407\nEpoch 3/25, Validation Loss: 1.751077281801324\nValidation QWK: 0.6369936034115138\nEpoch 4/25, Validation Loss: 1.3780939369870906\nValidation QWK: 0.7085787451984635\nEpoch 5/25, Validation Loss: 1.0503228562965727\nValidation QWK: 0.7677113510666316\nEpoch 6/25, Validation Loss: 0.8839446086632577\nValidation QWK: 0.8145258910558171\nEpoch 7/25, Validation Loss: 0.7161373448999304\nValidation QWK: 0.8452081956378057\nEpoch 8/25, Validation Loss: 0.6157208358248075\nValidation QWK: 0.8735936465916612\nEpoch 9/25, Validation Loss: 0.5373238974757362\nValidation QWK: 0.8897817061738316\nEpoch 10/25, Validation Loss: 0.4557776728220153\nValidation QWK: 0.9185859667916444\nEpoch 11/25, Validation Loss: 0.4734198871934623\nValidation QWK: 0.9166221272047034\nEpoch 12/25, Validation Loss: 0.4414800354524663\nValidation QWK: 0.9274312541918176\nEpoch 13/25, Validation Loss: 0.41366123120512877\nValidation QWK: 0.9217086646004582\nEpoch 14/25, Validation Loss: 0.4106620785437132\nValidation QWK: 0.9238838084991932\nEpoch 15/25, Validation Loss: 0.40875699776306484\nValidation QWK: 0.917190635451505\nEpoch 16/25, Validation Loss: 0.3838115585477729\nValidation QWK: 0.9284557235421166\nEpoch 17/25, Validation Loss: 0.39299950761753216\nValidation QWK: 0.933817594834544\nEpoch 18/25, Validation Loss: 0.3896361633873822\nValidation QWK: 0.9308260577568839\nEpoch 19/25, Validation Loss: 0.3735678021452929\nValidation QWK: 0.9274388605213653\nEpoch 21/25, Validation Loss: 0.3797593518045911\nValidation QWK: 0.9340115111765493\nEpoch 22/25, Validation Loss: 0.41351013107780826\nValidation QWK: 0.9230769230769231\nEpoch 23/25, Validation Loss: 0.2960493441736489\nValidation QWK: 0.9373326191751473\nEpoch 24/25, Validation Loss: 0.25221827047828\nValidation QWK: 0.9562626946513202\nEpoch 25/25, Validation Loss: 0.22856748038739488\nValidation QWK: 0.9595049105341047\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/46.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b4e680f2ec94ba9aed19888837476b6"}},"metadata":{}},{"name":"stdout","text":"Model:  resnet18\nEpoch 1/25, Validation Loss: 1.605070622343766\nValidation QWK: 0.19176447185199919\nEpoch 2/25, Validation Loss: 1.6010362474541915\nValidation QWK: 0.22252909844150726\nEpoch 3/25, Validation Loss: 1.598652854300382\nValidation QWK: 0.24126488385711498\nEpoch 4/25, Validation Loss: 1.595442246972469\nValidation QWK: 0.24253144654088055\nEpoch 5/25, Validation Loss: 1.5922631673645555\nValidation QWK: 0.2909020668340738\nEpoch 6/25, Validation Loss: 1.58815962808174\nValidation QWK: 0.28750237056703964\nEpoch 7/25, Validation Loss: 1.585352477274443\nValidation QWK: 0.32906143987938186\nEpoch 8/25, Validation Loss: 1.5828566174758107\nValidation QWK: 0.341776798825257\nEpoch 9/25, Validation Loss: 1.5801162928865666\nValidation QWK: 0.3560521415270018\nEpoch 10/25, Validation Loss: 1.5761517390870212\nValidation QWK: 0.36646307606885065\nEpoch 11/25, Validation Loss: 1.575258445321468\nValidation QWK: 0.38417058185760755\nEpoch 12/25, Validation Loss: 1.5758289286964817\nValidation QWK: 0.36810042458925607\nEpoch 13/25, Validation Loss: 1.5745733056152076\nValidation QWK: 0.39032316302581693\nEpoch 14/25, Validation Loss: 1.5748418715962194\nValidation QWK: 0.38195707530010914\nEpoch 15/25, Validation Loss: 1.5736804782298572\nValidation QWK: 0.3999272197962155\nEpoch 16/25, Validation Loss: 1.5737336351160418\nValidation QWK: 0.3989862418537292\nEpoch 17/25, Validation Loss: 1.5729409749047798\nValidation QWK: 0.3946986201888163\nEpoch 18/25, Validation Loss: 1.5718387260771634\nValidation QWK: 0.3924514474166362\nEpoch 19/25, Validation Loss: 1.5728996009157414\nValidation QWK: 0.39799031042526467\nEpoch 20/25, Validation Loss: 1.572456483255353\nValidation QWK: 0.3893711248892826\nEpoch 21/25, Validation Loss: 1.5728422842527692\nValidation QWK: 0.3835021707670043\nEpoch 22/25, Validation Loss: 1.5723500879187333\nValidation QWK: 0.391709116458809\nEpoch 23/25, Validation Loss: 1.5657001733779907\nValidation QWK: 0.43776223776223777\nEpoch 24/25, Validation Loss: 1.5586135303765012\nValidation QWK: 0.44026018486819585\nEpoch 25/25, Validation Loss: 1.5534051426670008\nValidation QWK: 0.4567859554355166\n","output_type":"stream"}]},{"cell_type":"code","source":"final_predictions_val, final_kappa_val = predict_ensemble(models, val_csv_file,val_root_dir)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T23:33:00.026529Z","iopub.execute_input":"2024-06-23T23:33:00.026822Z","iopub.status.idle":"2024-06-23T23:33:12.783893Z","shell.execute_reply.started":"2024-06-23T23:33:00.026796Z","shell.execute_reply":"2024-06-23T23:33:12.782918Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Final averaged predictions shape: (1805, 5)\nFinal Kappa: 0.9591809241546545\n","output_type":"stream"}]},{"cell_type":"code","source":"final_predictions, final_kappa = predict_ensemble(models, test_csv_file,test_root_dir)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T23:33:12.785414Z","iopub.execute_input":"2024-06-23T23:33:12.786133Z","iopub.status.idle":"2024-06-23T23:36:25.495757Z","shell.execute_reply.started":"2024-06-23T23:33:12.786099Z","shell.execute_reply":"2024-06-23T23:36:25.494828Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Final averaged predictions shape: (1928, 5)\nGround truth labels are not available in the test CSV file.\n","output_type":"stream"}]},{"cell_type":"code","source":"thresholds = [0.5, 1.5, 2.5, 3.5]\nfinal_classes = np.digitize(final_predictions, bins=thresholds)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T23:36:25.497002Z","iopub.execute_input":"2024-06-23T23:36:25.497292Z","iopub.status.idle":"2024-06-23T23:36:25.501975Z","shell.execute_reply.started":"2024-06-23T23:36:25.497267Z","shell.execute_reply":"2024-06-23T23:36:25.501059Z"},"trusted":true},"execution_count":31,"outputs":[]}]}