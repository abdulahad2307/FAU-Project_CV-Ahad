{"cells":[{"cell_type":"code","execution_count":89,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T17:02:18.676432Z","iopub.status.busy":"2024-06-23T17:02:18.676052Z","iopub.status.idle":"2024-06-23T17:02:18.683508Z","shell.execute_reply":"2024-06-23T17:02:18.682537Z","shell.execute_reply.started":"2024-06-23T17:02:18.676401Z"},"trusted":true},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import cohen_kappa_score\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import cv2\n","from PIL import Image\n","import timm\n","from multiprocessing import Pool\n","from tqdm import tqdm\n","from torchvision import transforms\n","from torch.optim.lr_scheduler import LambdaLR"]},{"cell_type":"code","execution_count":90,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T17:02:18.685373Z","iopub.status.busy":"2024-06-23T17:02:18.684961Z","iopub.status.idle":"2024-06-23T17:02:18.697648Z","shell.execute_reply":"2024-06-23T17:02:18.696851Z","shell.execute_reply.started":"2024-06-23T17:02:18.685345Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["No such directories\n"]}],"source":["## for removing file if required\n","import shutil\n","\n","try:\n","    shutil.rmtree(\"/kaggle/working/train\")\n","    \n","    model_file_to_delete =\"/kaggle/working/models\"\n","\n","    if os.path.isfile(model_file_to_delete):\n","        os.remove(model_file_to_delete)\n","    \n","except:\n","    print(\"No such directories\")"]},{"cell_type":"markdown","metadata":{},"source":["### Loading Data"]},{"cell_type":"code","execution_count":91,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T17:02:18.699700Z","iopub.status.busy":"2024-06-23T17:02:18.699355Z","iopub.status.idle":"2024-06-23T17:02:18.708402Z","shell.execute_reply":"2024-06-23T17:02:18.707543Z","shell.execute_reply.started":"2024-06-23T17:02:18.699672Z"},"trusted":true},"outputs":[],"source":["def load_data(data_dir):\n","    train_csv = os.path.join(data_dir, 'train.csv')\n","    test_csv = os.path.join(data_dir, 'test.csv')\n","    \n","    train = pd.read_csv(train_csv)\n","    test = pd.read_csv(test_csv)\n","    \n","    train_dir = os.path.join(data_dir, 'train_images/')\n","    test_dir = os.path.join(data_dir, 'test_images/')\n","    \n","    train['file_path'] = train['id_code'].map(lambda x: os.path.join(train_dir, '{}.png'.format(x)))\n","    test['file_path'] = test['id_code'].map(lambda x: os.path.join(test_dir, '{}.png'.format(x)))\n","    \n","    train['file_name'] = train[\"id_code\"] + \".png\"\n","    test['file_name'] = test[\"id_code\"] + \".png\"\n","    \n","    train['diagnosis'] = train['diagnosis'].astype(str)\n","    \n","    return train, test"]},{"cell_type":"code","execution_count":92,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T17:02:18.709757Z","iopub.status.busy":"2024-06-23T17:02:18.709453Z","iopub.status.idle":"2024-06-23T17:02:18.744631Z","shell.execute_reply":"2024-06-23T17:02:18.743931Z","shell.execute_reply.started":"2024-06-23T17:02:18.709714Z"},"trusted":true},"outputs":[],"source":["data_dir = '/kaggle/input/aptos2019-blindness-detection/'\n","train_df, test_df = load_data(data_dir)"]},{"cell_type":"code","execution_count":93,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T17:02:18.747054Z","iopub.status.busy":"2024-06-23T17:02:18.746776Z","iopub.status.idle":"2024-06-23T17:02:18.758426Z","shell.execute_reply":"2024-06-23T17:02:18.756917Z","shell.execute_reply.started":"2024-06-23T17:02:18.747026Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(3662, 4)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_code</th>\n","      <th>diagnosis</th>\n","      <th>file_path</th>\n","      <th>file_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000c1434d8d7</td>\n","      <td>2</td>\n","      <td>/kaggle/input/aptos2019-blindness-detection/tr...</td>\n","      <td>000c1434d8d7.png</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>001639a390f0</td>\n","      <td>4</td>\n","      <td>/kaggle/input/aptos2019-blindness-detection/tr...</td>\n","      <td>001639a390f0.png</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0024cdab0c1e</td>\n","      <td>1</td>\n","      <td>/kaggle/input/aptos2019-blindness-detection/tr...</td>\n","      <td>0024cdab0c1e.png</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>002c21358ce6</td>\n","      <td>0</td>\n","      <td>/kaggle/input/aptos2019-blindness-detection/tr...</td>\n","      <td>002c21358ce6.png</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>005b95c28852</td>\n","      <td>0</td>\n","      <td>/kaggle/input/aptos2019-blindness-detection/tr...</td>\n","      <td>005b95c28852.png</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        id_code diagnosis                                          file_path  \\\n","0  000c1434d8d7         2  /kaggle/input/aptos2019-blindness-detection/tr...   \n","1  001639a390f0         4  /kaggle/input/aptos2019-blindness-detection/tr...   \n","2  0024cdab0c1e         1  /kaggle/input/aptos2019-blindness-detection/tr...   \n","3  002c21358ce6         0  /kaggle/input/aptos2019-blindness-detection/tr...   \n","4  005b95c28852         0  /kaggle/input/aptos2019-blindness-detection/tr...   \n","\n","          file_name  \n","0  000c1434d8d7.png  \n","1  001639a390f0.png  \n","2  0024cdab0c1e.png  \n","3  002c21358ce6.png  \n","4  005b95c28852.png  "]},"execution_count":93,"metadata":{},"output_type":"execute_result"}],"source":["print(train_df.shape)\n","train_df.head()"]},{"cell_type":"code","execution_count":94,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T17:02:18.760629Z","iopub.status.busy":"2024-06-23T17:02:18.759627Z","iopub.status.idle":"2024-06-23T17:02:18.771172Z","shell.execute_reply":"2024-06-23T17:02:18.770411Z","shell.execute_reply.started":"2024-06-23T17:02:18.760593Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(1928, 3)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_code</th>\n","      <th>file_path</th>\n","      <th>file_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0005cfc8afb6</td>\n","      <td>/kaggle/input/aptos2019-blindness-detection/te...</td>\n","      <td>0005cfc8afb6.png</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>003f0afdcd15</td>\n","      <td>/kaggle/input/aptos2019-blindness-detection/te...</td>\n","      <td>003f0afdcd15.png</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>006efc72b638</td>\n","      <td>/kaggle/input/aptos2019-blindness-detection/te...</td>\n","      <td>006efc72b638.png</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>00836aaacf06</td>\n","      <td>/kaggle/input/aptos2019-blindness-detection/te...</td>\n","      <td>00836aaacf06.png</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>009245722fa4</td>\n","      <td>/kaggle/input/aptos2019-blindness-detection/te...</td>\n","      <td>009245722fa4.png</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        id_code                                          file_path  \\\n","0  0005cfc8afb6  /kaggle/input/aptos2019-blindness-detection/te...   \n","1  003f0afdcd15  /kaggle/input/aptos2019-blindness-detection/te...   \n","2  006efc72b638  /kaggle/input/aptos2019-blindness-detection/te...   \n","3  00836aaacf06  /kaggle/input/aptos2019-blindness-detection/te...   \n","4  009245722fa4  /kaggle/input/aptos2019-blindness-detection/te...   \n","\n","          file_name  \n","0  0005cfc8afb6.png  \n","1  003f0afdcd15.png  \n","2  006efc72b638.png  \n","3  00836aaacf06.png  \n","4  009245722fa4.png  "]},"execution_count":94,"metadata":{},"output_type":"execute_result"}],"source":["print(test_df.shape)\n","test_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["### Pre-Processing"]},{"cell_type":"code","execution_count":95,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T17:02:18.772723Z","iopub.status.busy":"2024-06-23T17:02:18.772391Z","iopub.status.idle":"2024-06-23T17:02:18.780842Z","shell.execute_reply":"2024-06-23T17:02:18.780004Z","shell.execute_reply.started":"2024-06-23T17:02:18.772700Z"},"trusted":true},"outputs":[],"source":["def crop_img(img, percentage):\n","    \n","    img_arr = np.array(img)\n","    img_gray = cv2.cvtColor(img_arr, cv2.COLOR_BGR2GRAY)\n","    \n","    threshold = img_gray > 0.1 * np.mean(img_gray[img_gray != 0])\n","    row_sums = np.sum(threshold, axis=1)\n","    col_sums = np.sum(threshold, axis=0)\n","    \n","    rows = np.where(row_sums > img_arr.shape[1] * percentage)[0]\n","    cols = np.where(col_sums > img_arr.shape[0] * percentage)[0]\n","    \n","    min_row, min_col = np.min(rows), np.min(cols)\n","    max_row, max_col = np.max(rows), np.max(cols)\n","    \n","    crop_img = img_arr[min_row : max_row + 1, min_col : max_col + 1]\n","    \n","    return Image.fromarray(crop_img)"]},{"cell_type":"code","execution_count":96,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T17:02:18.782951Z","iopub.status.busy":"2024-06-23T17:02:18.782162Z","iopub.status.idle":"2024-06-23T17:02:18.791919Z","shell.execute_reply":"2024-06-23T17:02:18.791117Z","shell.execute_reply.started":"2024-06-23T17:02:18.782919Z"},"trusted":true},"outputs":[],"source":["def resize_maintain_aspect(img, desired_size):\n","    old_width, old_height = img.size\n","    aspect_ratio = old_width / old_height\n","\n","    if aspect_ratio > 1:\n","        new_width = desired_size\n","        new_height = int(desired_size / aspect_ratio)\n","    else:\n","        new_height = desired_size\n","        new_width = int(desired_size * aspect_ratio)\n","\n","    resized_img = img.resize((new_width, new_height), Image.ANTIALIAS)\n","    \n","    padded_image = Image.new(\"RGB\", (desired_size, desired_size))\n","    x_offset = (desired_size - new_width) // 2\n","    y_offset = (desired_size - new_height) // 2\n","    padded_image.paste(resized_img, (x_offset, y_offset))\n","    \n","    return padded_image"]},{"cell_type":"code","execution_count":97,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T17:02:18.793442Z","iopub.status.busy":"2024-06-23T17:02:18.793166Z","iopub.status.idle":"2024-06-23T17:02:18.800486Z","shell.execute_reply":"2024-06-23T17:02:18.799794Z","shell.execute_reply.started":"2024-06-23T17:02:18.793414Z"},"trusted":true},"outputs":[],"source":["def save_single(args):\n","    image_path, output_path_folder, percentage, output_size = args\n","    image = Image.open(image_path)\n","    \n","    # Display the image\n","    #plt.imshow(image)\n","    #plt.title('Original Image')\n","    #plt.show()\n","    \n","    croped_img = crop_img(image,percentage)\n","    image_resized = resize_maintain_aspect(croped_img, desired_size=output_size[0])\n","    \n","    #print(output_path_folder)\n","    #print(image_path)\n","    output_image_path = os.path.basename(image_path)\n","    # Save the resized image\n","    output_file_path = os.path.join(output_path_folder, output_image_path)\n","    #print(output_file_path)\n","    image_resized.save(output_file_path)"]},{"cell_type":"code","execution_count":98,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T17:02:18.801884Z","iopub.status.busy":"2024-06-23T17:02:18.801529Z","iopub.status.idle":"2024-06-23T17:02:18.809536Z","shell.execute_reply":"2024-06-23T17:02:18.808778Z","shell.execute_reply.started":"2024-06-23T17:02:18.801861Z"},"trusted":true},"outputs":[],"source":["def fast_image_resize(df, output_path_folder, percentage, output_size=None):\n","    \"\"\"Uses multiprocessing to make it fast\"\"\"\n","    if not output_size:\n","        warnings.warn(\"Need to specify output_size! For example: output_size=100\")\n","        return\n","\n","    if not os.path.exists(output_path_folder):\n","        os.makedirs(output_path_folder)\n","        \n","    jobs = []\n","    for df_item in range(len(df)):\n","        image_path = df.file_path.iloc[df_item]\n","        #print(image_path)\n","        job = (image_path, output_path_folder, percentage, output_size)\n","        jobs.append(job)\n","    \n","    \"\"\"\n","    results = []\n","    for job in tqdm(jobs, total=len(jobs)):\n","        result = save_single(job)\n","        results.append(result)\n","    \"\"\"\n","    with Pool() as p:\n","        list(tqdm(p.imap_unordered(save_single, jobs), total=len(jobs)))"]},{"cell_type":"code","execution_count":99,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T17:02:18.813437Z","iopub.status.busy":"2024-06-23T17:02:18.813162Z","iopub.status.idle":"2024-06-23T17:07:03.996970Z","shell.execute_reply":"2024-06-23T17:07:03.995806Z","shell.execute_reply.started":"2024-06-23T17:02:18.813415Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/3662 [00:00<?, ?it/s]/tmp/ipykernel_34/3153832717.py:12: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n","  resized_img = img.resize((new_width, new_height), Image.ANTIALIAS)\n","  0%|          | 1/3662 [00:00<08:49,  6.92it/s]/tmp/ipykernel_34/3153832717.py:12: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n","  resized_img = img.resize((new_width, new_height), Image.ANTIALIAS)\n","  0%|          | 2/3662 [00:00<17:37,  3.46it/s]/tmp/ipykernel_34/3153832717.py:12: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n","  resized_img = img.resize((new_width, new_height), Image.ANTIALIAS)\n","/tmp/ipykernel_34/3153832717.py:12: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n","  resized_img = img.resize((new_width, new_height), Image.ANTIALIAS)\n","100%|██████████| 3662/3662 [04:44<00:00, 12.85it/s]\n"]}],"source":["percentage = 0.01\n","fast_image_resize(train_df, \"/kaggle/working/train/images_resized_150/\",percentage, output_size=(100, 100))"]},{"cell_type":"markdown","metadata":{},"source":["### Model Implementation - Ensambling \n","#### EfficientNet_b0-b7"]},{"cell_type":"code","execution_count":100,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T17:07:03.998882Z","iopub.status.busy":"2024-06-23T17:07:03.998495Z","iopub.status.idle":"2024-06-23T17:07:04.010823Z","shell.execute_reply":"2024-06-23T17:07:04.009939Z","shell.execute_reply.started":"2024-06-23T17:07:03.998850Z"},"trusted":true},"outputs":[],"source":["class BlindnessDataset(Dataset):\n","    def __init__(self, csv_file, root_dir, transform=None, augmentations=None, max_count=None, test=False):\n","        self.annotations = pd.read_csv(csv_file)\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        #self.augmentations = augmentations\n","        self.max_count = max_count\n","        self.test = test\n","        \n","        if not test:\n","            self.class_counts = self.annotations['diagnosis'].value_counts().sort_index()\n","        else:\n","            self.class_counts = None\n","        \n","        if max_count:\n","            self.oversample(max_count)\n","    \n","    def oversample(self, max_count): ## Over sampling classes to balance\n","        samples = []\n","        for diagnosis in self.class_counts.index:\n","            class_samples = self.annotations[self.annotations['diagnosis'] == diagnosis]\n","            oversampled_class = class_samples.sample(max_count, replace=True)\n","            samples.append(oversampled_class)\n","        self.annotations = pd.concat(samples).reset_index(drop=True)\n","    \n","    def __len__(self):\n","        return len(self.annotations)\n","    \n","    def __getitem__(self, idx):\n","        img_name = os.path.join(self.root_dir, self.annotations.iloc[idx, 0] + '.png')\n","        image = Image.open(img_name).convert('RGB')\n","        \n","        if self.transform:\n","            image = self.transform(image)\n","        \n","        if self.test:\n","            return image\n","                \n","        label = int(self.annotations.iloc[idx, 1])\n","        return image, label"]},{"cell_type":"code","execution_count":101,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T17:07:04.012251Z","iopub.status.busy":"2024-06-23T17:07:04.011977Z","iopub.status.idle":"2024-06-23T17:07:04.023967Z","shell.execute_reply":"2024-06-23T17:07:04.023106Z","shell.execute_reply.started":"2024-06-23T17:07:04.012229Z"},"trusted":true},"outputs":[],"source":["def select_model(model_name):\n","    if model_name == 'efficientnet_b0':\n","        return timm.create_model('efficientnet_b0', pretrained=True, num_classes=5)\n","    elif model_name == 'efficientnet_b1':\n","        return timm.create_model('efficientnet_b1', pretrained=True, num_classes=5)\n","    elif model_name == 'efficientnet_b2':\n","        return timm.create_model('efficientnet_b2', pretrained=True, num_classes=5)\n","    elif model_name == 'efficientnet_b3':\n","        return timm.create_model('efficientnet_b3', pretrained=True, num_classes=5)\n","    elif model_name == 'efficientnet_b4':\n","        return timm.create_model('efficientnet_b4', pretrained=True, num_classes=5)\n","    elif model_name == 'efficientnet_b5':\n","        return timm.create_model('efficientnet_b5', pretrained=True, num_classes=5)\n","    elif model_name == 'efficientnet_b6':\n","        return timm.create_model('efficientnet_b6', pretrained=False, num_classes=5)\n","    elif model_name == 'efficientnet_b7':\n","        return timm.create_model('efficientnet_b7', pretrained=False, num_classes=5)\n","    "]},{"cell_type":"code","execution_count":102,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T17:07:04.025314Z","iopub.status.busy":"2024-06-23T17:07:04.025040Z","iopub.status.idle":"2024-06-23T17:07:04.036422Z","shell.execute_reply":"2024-06-23T17:07:04.035518Z","shell.execute_reply.started":"2024-06-23T17:07:04.025281Z"},"trusted":true},"outputs":[],"source":["def lr_schedule(epoch):\n","    if epoch < 10:\n","        return 5e-4\n","    elif epoch < 16:\n","        return 1e-4\n","    elif epoch < 22:\n","        return 1e-5\n","    else:\n","        return 1e-3\n","        "]},{"cell_type":"code","execution_count":103,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T17:07:04.038135Z","iopub.status.busy":"2024-06-23T17:07:04.037627Z","iopub.status.idle":"2024-06-23T17:07:04.051213Z","shell.execute_reply":"2024-06-23T17:07:04.050297Z","shell.execute_reply.started":"2024-06-23T17:07:04.038111Z"},"trusted":true},"outputs":[],"source":["def train_model(model_name,train_loader,valid_loader):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = select_model(model_name).to(device)\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters())\n","    \n","    def lambda_epoch(epoch):\n","        return lr_schedule(epoch)\n","    \n","    def quadratic_weighted_kappa(y_true, y_pred):\n","        return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n","    \n","    scheduler = LambdaLR(optimizer,lr_lambda = lambda_epoch)\n","    best_kappa = 0.0\n","    \n","    print(\"Model: \", model_name)\n","    \n","    for epoch in range(25):\n","        model.train()\n","        for images, labels in train_loader:\n","            if isinstance(images, Image.Image):  # Check if the image is a PIL image\n","                transform = transforms.ToTensor()\n","                images = transform(images)\n","            else:\n","                images = images\n","                \n","            images, labels = images.to(device), labels.to(device)\n","            \n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","        scheduler.step()\n","        \n","        model.eval()\n","        val_loss = 0\n","        val_preds = []\n","        val_labels_epoch = []\n","        with torch.no_grad():\n","            for images, labels in valid_loader:\n","                images, labels = images.to(device), labels.to(device)\n","                outputs = model(images)\n","                loss = criterion(outputs,labels)\n","                val_loss += loss.item()\n","                preds = torch.argmax(outputs, dim=1)\n","                val_labels_epoch.extend(labels.cpu().numpy())\n","                val_preds.extend(preds.cpu().numpy())\n","        \n","        #val_predictions.append(val_preds)\n","        #val_labels.append(val_labels_epoch)\n","        \n","        kappa = quadratic_weighted_kappa(val_labels_epoch, val_preds)\n","        print(f\"Epoch {epoch+1}/{25}, Validation Loss: {val_loss / len(valid_loader)}\")\n","        print(f\"Validation QWK: {kappa}\")\n","        \n","        if kappa > best_kappa:\n","            best_kappa = kappa\n","            best_model = model.state_dict()\n","    \n","            \n","    model.load_state_dict(best_model)\n","    \n","    return model\n","\n","    "]},{"cell_type":"code","execution_count":104,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T17:07:04.052635Z","iopub.status.busy":"2024-06-23T17:07:04.052354Z","iopub.status.idle":"2024-06-23T17:07:04.062890Z","shell.execute_reply":"2024-06-23T17:07:04.062119Z","shell.execute_reply.started":"2024-06-23T17:07:04.052609Z"},"trusted":true},"outputs":[],"source":["csv_file = '/kaggle/input/aptos2019-blindness-detection/train.csv'\n","pros_img_dir = '/kaggle/working/train/images_resized_150'\n","test_csv_file = '/kaggle/input/aptos2019-blindness-detection/test.csv'\n","test_root_dir = '/kaggle/input/aptos2019-blindness-detection/test_images'\n","val_csv_file = '/kaggle/working/val.csv'\n","val_root_dir = '/kaggle/working/val_images/'\n","\n","os.makedirs(val_root_dir, exist_ok=True)"]},{"cell_type":"code","execution_count":105,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T17:07:04.064249Z","iopub.status.busy":"2024-06-23T17:07:04.063935Z","iopub.status.idle":"2024-06-23T17:07:04.071461Z","shell.execute_reply":"2024-06-23T17:07:04.070766Z","shell.execute_reply.started":"2024-06-23T17:07:04.064219Z"},"trusted":true},"outputs":[],"source":["transform = transforms.Compose([ \n","        transforms.Resize((224, 224)), transforms.ToTensor() \n","    ])"]},{"cell_type":"code","execution_count":106,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T17:07:04.072701Z","iopub.status.busy":"2024-06-23T17:07:04.072444Z","iopub.status.idle":"2024-06-23T17:07:04.089631Z","shell.execute_reply":"2024-06-23T17:07:04.088827Z","shell.execute_reply.started":"2024-06-23T17:07:04.072680Z"},"trusted":true},"outputs":[],"source":["## Loading the dataset for determination of the class counts\n","temp_dataset = BlindnessDataset(csv_file, pros_img_dir, transform=transform)\n","class_counts = temp_dataset.class_counts\n","max_count = class_counts.max()"]},{"cell_type":"code","execution_count":107,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T17:07:04.090844Z","iopub.status.busy":"2024-06-23T17:07:04.090573Z","iopub.status.idle":"2024-06-23T17:07:04.113653Z","shell.execute_reply":"2024-06-23T17:07:04.112970Z","shell.execute_reply.started":"2024-06-23T17:07:04.090822Z"},"trusted":true},"outputs":[],"source":["dataset = BlindnessDataset(csv_file, pros_img_dir, transform=transform, max_count=max_count)\n","train_indices, val_indices = train_test_split(list(range(len(dataset))), test_size=0.2, stratify=dataset.annotations.iloc[:, 1])\n","train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n","val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n","train_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler)\n","val_loader = DataLoader(dataset, batch_size=32, sampler=val_sampler)\n","        "]},{"cell_type":"code","execution_count":108,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T17:07:04.114935Z","iopub.status.busy":"2024-06-23T17:07:04.114658Z","iopub.status.idle":"2024-06-23T17:07:04.526320Z","shell.execute_reply":"2024-06-23T17:07:04.525287Z","shell.execute_reply.started":"2024-06-23T17:07:04.114914Z"},"trusted":true},"outputs":[],"source":["val_annotations = dataset.annotations.iloc[val_indices]\n","val_annotations.to_csv(val_csv_file, index=False)\n","\n","for idx in val_indices:\n","    img_name = dataset.annotations.iloc[idx, 0] + '.png'\n","    src_path = os.path.join(pros_img_dir, img_name)\n","    dst_path = os.path.join(val_root_dir, img_name)\n","    shutil.copy2(src_path, dst_path)"]},{"cell_type":"code","execution_count":109,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T17:07:04.527912Z","iopub.status.busy":"2024-06-23T17:07:04.527632Z","iopub.status.idle":"2024-06-23T17:07:04.534011Z","shell.execute_reply":"2024-06-23T17:07:04.533089Z","shell.execute_reply.started":"2024-06-23T17:07:04.527890Z"},"trusted":true},"outputs":[],"source":["def cross_validate_and_ensemble(train_loader, val_loader): \n","    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","    \n","    models = {'efficientnet_b0': [], 'efficientnet_b1': [], \n","              'efficientnet_b2': [], 'efficientnet_b3': [],\n","             'efficientnet_b4': [], 'efficientnet_b5': [],\n","             'efficientnet_b6': [], 'efficientnet_b7': []}\n","        \n","    for model_type in models.keys(): \n","        model = train_model(model_type, train_loader, val_loader) \n","        models[model_type].append(model) \n","    return models"]},{"cell_type":"code","execution_count":110,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T17:07:04.535415Z","iopub.status.busy":"2024-06-23T17:07:04.535120Z","iopub.status.idle":"2024-06-23T17:07:04.541503Z","shell.execute_reply":"2024-06-23T17:07:04.540732Z","shell.execute_reply.started":"2024-06-23T17:07:04.535391Z"},"trusted":true},"outputs":[],"source":["def get_predicted_labels(predictions):\n","    predicted_labels = np.argmax(predictions, axis=1)\n","    return predicted_labels"]},{"cell_type":"code","execution_count":111,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T17:07:04.542740Z","iopub.status.busy":"2024-06-23T17:07:04.542448Z","iopub.status.idle":"2024-06-23T17:07:04.550083Z","shell.execute_reply":"2024-06-23T17:07:04.549265Z","shell.execute_reply.started":"2024-06-23T17:07:04.542703Z"},"trusted":true},"outputs":[],"source":["def load_ground_truth_labels(test_csv_file):\n","    test_df = pd.read_csv(test_csv_file)\n","    if test_df.shape[1] > 1:\n","        ground_truth_labels = test_df.iloc[:, 1].values\n","    else:\n","        ground_truth_labels = None\n","    return ground_truth_labels"]},{"cell_type":"code","execution_count":112,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T17:07:04.551330Z","iopub.status.busy":"2024-06-23T17:07:04.551072Z","iopub.status.idle":"2024-06-23T17:07:04.558978Z","shell.execute_reply":"2024-06-23T17:07:04.558114Z","shell.execute_reply.started":"2024-06-23T17:07:04.551297Z"},"trusted":true},"outputs":[],"source":["def quadratic_weighted_kappa(y_true, y_pred):\n","    return cohen_kappa_score(y_true, y_pred, weights='quadratic')"]},{"cell_type":"code","execution_count":124,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T20:55:31.710912Z","iopub.status.busy":"2024-06-23T20:55:31.710089Z","iopub.status.idle":"2024-06-23T20:55:31.721277Z","shell.execute_reply":"2024-06-23T20:55:31.720310Z","shell.execute_reply.started":"2024-06-23T20:55:31.710878Z"},"trusted":true},"outputs":[],"source":["def predict_ensemble(models, test_csv_file,test_root_dir): \n","    transform = transforms.Compose([ transforms.Resize((224, 224)), transforms.ToTensor() ]) \n","    test_dataset = BlindnessDataset(test_csv_file, test_root_dir, transform=transform, test=True)\n","    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n","    predictions = []\n","    \n","    for model_type, model_list in models.items():\n","        for model in model_list:\n","            model.eval() \n","            model = model.to(device) \n","            model_preds = [] \n","            with torch.no_grad(): \n","                for images in test_loader: \n","                    images = images.to(device) \n","                    outputs = model(images) \n","                    preds = torch.softmax(outputs, dim=1) \n","                    model_preds.append(preds.cpu().numpy()) \n","            model_preds = np.concatenate(model_preds, axis=0)\n","            #print(f\"{model_type} model predictions shape: {model_preds.shape}\")\n","            predictions.append(model_preds)\n","    \n","    #print(f\"Number of model predictions: {len(predictions)}\")\n","    #for i, pred in enumerate(predictions):\n","        #print(f\"Shape of predictions from model {i+1}: {pred.shape}\")\n","    \n","    final_predictions = np.mean(predictions, axis=0)\n","    print(f\"Final averaged predictions shape: {final_predictions.shape}\")\n","    \n","    predicted_labels = get_predicted_labels(final_predictions)\n","    \n","    ground_truth_labels = load_ground_truth_labels(test_csv_file)\n","    \n","    if ground_truth_labels is not None:\n","        final_kappa = quadratic_weighted_kappa(ground_truth_labels, predicted_labels)\n","        print(\"Final Kappa:\", final_kappa)\n","    else:\n","        final_kappa = None\n","        print(\"Ground truth labels are not available in the test CSV file.\")\n","    \n","    return final_predictions, final_kappa"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["models = cross_validate_and_ensemble(train_loader, val_loader)"]},{"cell_type":"code","execution_count":125,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T20:55:38.880557Z","iopub.status.busy":"2024-06-23T20:55:38.879786Z","iopub.status.idle":"2024-06-23T20:55:59.986224Z","shell.execute_reply":"2024-06-23T20:55:59.985295Z","shell.execute_reply.started":"2024-06-23T20:55:38.880525Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Final averaged predictions shape: (1805, 5)\n","Final Kappa: 0.8683312866693955\n"]}],"source":["\n","final_predictions_val, final_kappa_val = predict_ensemble(models, val_csv_file,val_root_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["final_predictions, final_kappa = predict_ensemble(models, test_csv_file,test_root_dir)"]},{"cell_type":"code","execution_count":128,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T21:03:59.391682Z","iopub.status.busy":"2024-06-23T21:03:59.390543Z","iopub.status.idle":"2024-06-23T21:03:59.396792Z","shell.execute_reply":"2024-06-23T21:03:59.395779Z","shell.execute_reply.started":"2024-06-23T21:03:59.391635Z"},"trusted":true},"outputs":[],"source":["thresholds = [0.5, 1.5, 2.5, 3.5]\n","final_classes = np.digitize(final_predictions, bins=thresholds)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["save_predictions(final_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":875431,"sourceId":14774,"sourceType":"competition"}],"dockerImageVersionId":30732,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
